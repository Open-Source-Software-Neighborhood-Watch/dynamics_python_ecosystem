{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import math\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import hypernetx as hnx\n",
    "import powerlaw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import operator\n",
    "import collections\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "### [Section 1](#section1): Contribution Distributions Type \n",
    "### [Section 2](#section2): HyperNetwork Analysis\n",
    "### [Section 3](#section3): Bipartitie and Projection Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"section1\"></a>\n",
    "# Section 1:  Identify contribution distribution for each of the top 14 libraries and cpython. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data from pickle file see read_diles_convert_to_dict_simplified for process of pax_net\n",
    "pax_net = pickle.load(open(\"./Dependency Graphs/pax_net3.pkl\", \"rb\"))\n",
    "\n",
    "\n",
    "#list of top repos by paretian binning -- see PyPI Analytics  \n",
    "repos = [\"click\", \"cpython\", \"django\",\"matplotlib\",\"numpy\",\"odoo\",\"pandas\",\"pytest\",\"pytest-cov\",\"pyyaml\",\"requests\",\n",
    "         \"scipy\",\"setuptools\",\"six\",\"sphinx\"]\n",
    "        #'matplotlib', 'scipy', \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data structures to analyze data\n",
    "'''\n",
    "identify each contributors contribution to each library\n",
    "key: library\n",
    "value: list of contribution numbers\n",
    "\n",
    "purpose: build distribution histograms\n",
    "'''\n",
    "lib_counts_by_contrib = {}\n",
    "lib_by_pulls = {}\n",
    "lib_by_commits ={}\n",
    "'''\n",
    "identify each contributors contribution to each library by name\n",
    "key: library\n",
    "value dictionary of: \n",
    "     key2: github username\n",
    "     value2: number of contributions \n",
    "'''\n",
    "lib_producers = {}\n",
    "lib_producers_split ={}\n",
    "\n",
    "\n",
    "\n",
    "for repo in repos: \n",
    "        lib_counts_by_contrib[repo] = []\n",
    "        lib_producers[repo] = {}\n",
    "        lib_by_pulls[repo] =[]\n",
    "        lib_by_commits[repo] =[]\n",
    "        lib_producers_split[repo]={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['click', 'cpython', 'django', 'matplotlib', 'numpy', 'odoo', 'pandas', 'pytest', 'pytest-cov', 'pyyaml', 'requests', 'scipy', 'setuptools', 'six', 'sphinx'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Critical to this measurement is defining contributions\n",
    "#Contributions are defined as a successful pull (e.g. a pull request)\n",
    "#and a successful commit, these are mereley prxies as each user has their own technique for commits\n",
    "\n",
    "for k,v in pax_net.items(): \n",
    "        for lib in v[\"contributor\"]: \n",
    "            if lib in v[\"successful_pulls\"].keys():\n",
    "                pulls = v[\"successful_pulls\"][lib]\n",
    "            else: \n",
    "                pulls = 0\n",
    "            if lib in v[\"commits\"].keys(): \n",
    "                coms = v[\"commits\"][lib]\n",
    "            else:\n",
    "                coms = 0\n",
    "        \n",
    "            lib_counts_by_contrib[lib].append(coms+pulls)\n",
    "            lib_producers[lib][k] = coms+pulls\n",
    "            lib_by_pulls[lib].append(pulls)\n",
    "            lib_by_commits[lib].append(coms)\n",
    "            lib_producers_split[lib][k]= [coms,pulls]\n",
    "\n",
    "lib_by_commits.keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assess bin size\n",
    "county = 0\n",
    "for contrib in lib_counts_by_contrib['cpython']:\n",
    "    min_c = min(lib_counts_by_contrib['cpython'])\n",
    "    if contrib < min_c+48:\n",
    "        county +=1\n",
    "county, min_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "sns.histplot(lib_counts_by_contrib['cpython'], bins = 70)\n",
    "plt.title('Distribution of cPython Contributions', fontsize = 20, fontweight ='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_py = np.sort(lib_counts_by_contrib['cpython'])\n",
    "sorted_py = sorted_py[::-1]\n",
    "below_bend = []\n",
    "for i in sorted_py:\n",
    "    if i > 100: \n",
    "        below_bend.append(i)\n",
    "    else: \n",
    "        break\n",
    "percent_head = sum(below_bend)/sum(sorted_py)\n",
    "percent_head, len(below_bend)/len(sorted_py), len(below_bend), len(sorted_py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yvals=np.arange(len(sorted_py))/float(len(sorted_py)-1)\n",
    "sns.lineplot(x=sorted_py,y=yvals)\n",
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "plt.title('Distribution of cPython Contributions', fontsize = 24, fontweight ='bold')\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.tick_params(axis='y', labelsize=16)\n",
    "plt.ylabel('Pertcent of Contributors', fontsize=18)\n",
    "plt.xlabel('Number of Contributions', fontsize=18)\n",
    "style = dict(size=20, color='blue')\n",
    "plt.text(450, 0.6, \"5% (47) of contributors compromise 83% of contributions\", **style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "sns.histplot(lib_by_pulls['cpython'], bins = 70)\n",
    "plt.title('Distribution of Python Pulls', fontsize = 20, fontweight ='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "sns.histplot(lib_by_commits['cpython'], bins = 70)\n",
    "plt.title('Distribution of Python Commits', fontsize = 20, fontweight ='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram for each library\n",
    "\n",
    "#Due to the variance in scale of activity for each library instead of making a common y axis these plots are organized\n",
    "#from least to greatest total number of contributions. \n",
    "sorted_count =OrderedDict()\n",
    "# create sorted dictionary from least to greatest\n",
    "count_libs = []\n",
    "for k,v in lib_counts_by_contrib.items(): \n",
    "    if k == 'cpython':\n",
    "        pass\n",
    "    else:\n",
    "        count_libs.append((k,sum(v)))\n",
    "\n",
    "sorted_libs = sorted(count_libs, key=lambda tup: tup[1])\n",
    "\n",
    "for lib in sorted_libs: \n",
    "    sorted_count[lib[0]] = lib_counts_by_contrib[lib[0]]\n",
    "\n",
    "fig, ax = plt.subplots(7,2, figsize=(12,10))\n",
    "\n",
    "libs = list(sorted_count.keys())\n",
    "commits = list(sorted_count.values())\n",
    "count = 0\n",
    "for j in range(len(ax)):\n",
    "    for i in range(len(ax[j])):\n",
    "        sns.set()\n",
    "        #print (commits[count]) \n",
    "        ax[j][i].set_title(libs[count], fontsize = 15,fontweight='bold')\n",
    "        ax[j][i] = sns.histplot(commits[count],ax=ax[j][i], bins =70)\n",
    "        count +=1\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Contribution Distribution for Top 14 Libaries', position=(.5,1.05), fontsize=20, fontweight='bold')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram for each library\n",
    "\n",
    "#Due to the variance in scale of activity for each library instead of making a common y axis these plots are organized\n",
    "#from least to greatest total number of contributions. \n",
    "sorted_count =OrderedDict()\n",
    "# create sorted dictionary from least to greatest\n",
    "count_libs = []\n",
    "for k,v in lib_by_pulls.items(): \n",
    "     if k == 'cpython':\n",
    "        pass\n",
    "     else:\n",
    "        count_libs.append((k,sum(v)))\n",
    "\n",
    "sorted_libs = sorted(count_libs, key=lambda tup: tup[1])\n",
    "\n",
    "for lib in sorted_libs: \n",
    "    sorted_count[lib[0]] = lib_by_pulls[lib[0]]\n",
    "\n",
    "fig, ax = plt.subplots(7,2, figsize=(12,10))\n",
    "\n",
    "libs = list(sorted_count.keys())\n",
    "commits = list(sorted_count.values())\n",
    "count = 0\n",
    "for j in range(len(ax)):\n",
    "    for i in range(len(ax[j])):\n",
    "        sns.set()\n",
    "        #print (commits[count]) \n",
    "        ax[j][i].set_title(libs[count], fontsize = 15,fontweight='bold')\n",
    "        ax[j][i] = sns.histplot(commits[count],ax=ax[j][i], bins =70)\n",
    "        count +=1\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Pull Distribution for Top 14 Libaries', position=(.5,1.05), fontsize=20, fontweight='bold')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram for each library\n",
    "\n",
    "#Due to the variance in scale of activity for each library instead of making a common y axis these plots are organized\n",
    "#from least to greatest total number of contributions. \n",
    "sorted_count =OrderedDict()\n",
    "# create sorted dictionary from least to greatest\n",
    "count_libs = []\n",
    "for k,v in lib_by_commits.items(): \n",
    "     if k == 'cpython':\n",
    "        pass\n",
    "     else:\n",
    "        count_libs.append((k,sum(v)))\n",
    "\n",
    "sorted_libs = sorted(count_libs, key=lambda tup: tup[1])\n",
    "\n",
    "for lib in sorted_libs: \n",
    "    sorted_count[lib[0]] = lib_by_commits[lib[0]]\n",
    "\n",
    "fig, ax = plt.subplots(7,2, figsize=(12,10))\n",
    "\n",
    "libs = list(sorted_count.keys())\n",
    "commits = list(sorted_count.values())\n",
    "count = 0\n",
    "for j in range(len(ax)):\n",
    "    for i in range(len(ax[j])):\n",
    "        sns.set()\n",
    "        #print (commits[count]) \n",
    "        ax[j][i].set_title(libs[count], fontsize = 15,fontweight='bold')\n",
    "        ax[j][i] = sns.histplot(commits[count],ax=ax[j][i], bins =70)\n",
    "        count +=1\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Commit Distribution for Top 14 Libaries', position=(.5,1.05), fontsize=20, fontweight='bold')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Distribution of the Top 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fit(distro):\n",
    "    dist_results = {\"Distribution 1\": [], \"Distribution 2\":[], \"R\":[], \"p\":[]}\n",
    "    best = \"\" \n",
    "\n",
    "    results = powerlaw.Fit(distro)\n",
    "    type_heavy = list(results.supported_distributions.keys())\n",
    "    for ty in type_heavy:\n",
    "        for other in type_heavy: \n",
    "            if ty != other: \n",
    "                R, p = results.distribution_compare(ty, other)\n",
    "                dist_results[\"Distribution 1\"].append(ty)\n",
    "                dist_results[\"Distribution 2\"].append(other)\n",
    "                dist_results[\"R\"].append(R)\n",
    "                dist_results['p'].append(p)\n",
    "\n",
    "    count_check = 0\n",
    "    base = \"power_law\"\n",
    "    #Get best fit\n",
    "    for i in range(len(dist_results[\"Distribution 1\"])):    \n",
    "        dist = dist_results[\"Distribution 1\"][i]\n",
    "        if base != dist: \n",
    "            base = dist\n",
    "            count_check = 0\n",
    "            if dist_results[\"R\"][i] > 0: \n",
    "                count_check += 1\n",
    "        else: \n",
    "            if dist_results[\"R\"][i] > 0: \n",
    "                count_check += 1\n",
    "            if count_check == 5: \n",
    "                best = dist\n",
    "\n",
    "    #Put results in table for reference           \n",
    "    dist_results = pd.DataFrame.from_dict(dist_results)\n",
    "    #see distribution type\n",
    "    return best, dist_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for k,v, in lib_counts_by_contrib.items(): \n",
    "    best_fit, dist_results = get_fit(v)\n",
    "    results[k] = best_fit\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in results.items(): \n",
    "    print(k,v,sum(lib_counts_by_contrib[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in lib_counts_by_contrib.items():\n",
    "    print(k,len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"section2\"></a>\n",
    "\n",
    "# Section 2: HyperNetwork Analysis\n",
    "\n",
    "As contributors and libraries represent a disjoint set we examine the network as a hypergraph. An then with various biparitie and projections. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data structure for hypergraphs\n",
    "\n",
    "'''\n",
    "hype_contrib\n",
    "key : name of library\n",
    "value  list of contributors\n",
    "'''\n",
    "hyper_contrib = {}\n",
    "'''\n",
    "H_star\n",
    "key: name of contributor\n",
    "value: list of libraries\n",
    "'''\n",
    "H_star = {}\n",
    "\n",
    "for k, v in lib_producers.items(): \n",
    "    hyper_contrib[k] = list(v.keys())\n",
    "    for p in v:\n",
    "        if p not in H_star.keys(): \n",
    "            H_star[p] = [k]\n",
    "        else: \n",
    "            H_star[p].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to file\n",
    "hyper_contrib2 = hnx.Hypergraph(hyper_contrib)\n",
    "H_star_contrib = hnx.Hypergraph(H_star)\n",
    "\n",
    "with open(\"data/h_star_contrib.pkl\", 'wb') as pkl_object:\n",
    "    pickle.dump(H_star_contrib, pkl_object)\n",
    "with open(\"data/hyper_contrib.pkl\", 'wb') as pkl_object:\n",
    "    pickle.dump(hyper_contrib2, pkl_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/h_star_contrib.pkl\", 'rb') as pkl_object:\n",
    "    H_star_hyper = pickle.load(pkl_object)\n",
    "with open(\"data/hyper_contrib.pkl\", 'rb') as pkl_object:\n",
    "    hyper = pickle.load(pkl_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_stats = hnx.reports.descriptive_stats.info(hyper)\n",
    "hyper_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_central = hnx.algorithms.s_centrality_measures.s_betweenness_centrality(hyper)\n",
    "s_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sorted = sorted(s_central.items(), key=operator.itemgetter(1))\n",
    "b_sorted_dict = collections.OrderedDict(b_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#b_sorted = sorted(centrality.items(), key=operator.itemgetter(1))\n",
    "#b_sorted_dict = collections.OrderedDict(b_sorted)\n",
    "print('Building graph...')\n",
    "\n",
    "sns.set(style=\"darkgrid\",rc={'figure.figsize':(10,10)}, font_scale = 2 )\n",
    "plt.title('Python Libraries by S-Centrality (Top 14)', fontweight = 'bold')\n",
    "#plt.figure(figsize= )\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Library', fontweight='bold')\n",
    "plt.ylabel('S Centrality', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "x_plot = list(b_sorted_dict.keys())[-14:]\n",
    "y_plot = list(b_sorted_dict.values())[-14:]\n",
    "x_plot.reverse()\n",
    "y_plot.reverse()\n",
    "sns.barplot(x=x_plot, y=y_plot)\n",
    "\n",
    "\n",
    "plt.savefig('hypercentralities_graph.png', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.drawing.draw(hyper, with_node_labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapsed nodes version\n",
    "hnx.drawing.draw(hyper_contrib.collapse_nodes(), with_node_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"section3\"></a>\n",
    "##  Section 3: Bipartite and Projection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Ratio Head to tail: 0.1346153846153846 and Ratio Weight: 0.3881278538812785\n",
      "Ratio Head to tail: 0.4 and Ratio Weight: 0.46\n",
      "Ratio Head to tail: 1.0 and Ratio Weight: 0.6666666666666666\n",
      "7 52\n",
      "Ratio Head to tail: 0.09965635738831616 and Ratio Weight: 0.1062087859577586\n",
      "Ratio Head to tail: 0.3384615384615385 and Ratio Weight: 0.2990812779341169\n",
      "Ratio Head to tail: 0.375 and Ratio Weight: 0.7663742690058479\n",
      "Ratio Head to tail: 1.0 and Ratio Weight: 0.37805983680870353\n",
      "87 873\n",
      "Ratio Head to tail: 0.07982261640798226 and Ratio Weight: 0.18463256506498743\n",
      "Ratio Head to tail: 0.23076923076923078 and Ratio Weight: 0.2825542072806843\n",
      "Ratio Head to tail: 0.35 and Ratio Weight: 0.47644501879699247\n",
      "Ratio Head to tail: 0.4 and Ratio Weight: 0.9057427515952088\n",
      "Ratio Head to tail: 1.0 and Ratio Weight: 0.48610880053235733\n",
      "144 1804\n",
      "Ratio Head to tail: 0.09937888198757763 and Ratio Weight: 0.12084302031739613\n",
      "Ratio Head to tail: 0.2972972972972973 and Ratio Weight: 0.35808909328025257\n",
      "Ratio Head to tail: 0.5714285714285714 and Ratio Weight: 0.5168141592920354\n",
      "48 483\n",
      "Ratio Head to tail: 0.07930367504835589 and Ratio Weight: 0.1286060186786579\n",
      "Ratio Head to tail: 0.3225806451612903 and Ratio Weight: 0.34165583812882866\n",
      "Ratio Head to tail: 0.42857142857142855 and Ratio Weight: 0.5413447782546496\n",
      "Ratio Head to tail: 0.5 and Ratio Weight: 0.8066683897647972\n",
      "41 517\n",
      "Ratio Head to tail: 0.14690130068859986 and Ratio Weight: 0.10390417620346469\n",
      "Ratio Head to tail: 0.32413793103448274 and Ratio Weight: 0.38670195505800276\n",
      "Ratio Head to tail: 0.38235294117647056 and Ratio Weight: 0.6685447439216283\n",
      "Ratio Head to tail: 0.8571428571428571 and Ratio Weight: 0.4953320683111955\n",
      "192 1307\n",
      "Ratio Head to tail: 0.1324828263002944 and Ratio Weight: 0.2772140221402214\n",
      "Ratio Head to tail: 0.16379310344827586 and Ratio Weight: 0.4012409513960703\n",
      "Ratio Head to tail: 0.46153846153846156 and Ratio Weight: 0.42049210429673156\n",
      "Ratio Head to tail: 1.0 and Ratio Weight: 0.3704076497232008\n",
      "135 1019\n",
      "Ratio Head to tail: 0.07006369426751592 and Ratio Weight: 0.1689907038512616\n",
      "Ratio Head to tail: 0.375 and Ratio Weight: 0.24360033030553263\n",
      "Ratio Head to tail: 0.5 and Ratio Weight: 0.7165131112686038\n",
      "11 157\n",
      "Ratio Head to tail: 0.375 and Ratio Weight: 0.07168458781362007\n",
      "Ratio Head to tail: 0.5 and Ratio Weight: 0.48404255319148937\n",
      "3 8\n",
      "Ratio Head to tail: 0.15 and Ratio Weight: 0.2862903225806452\n",
      "Ratio Head to tail: 0.5 and Ratio Weight: 1.4313725490196079\n",
      "3 20\n",
      "Ratio Head to tail: 0.05714285714285714 and Ratio Weight: 0.21779548472775564\n",
      "Ratio Head to tail: 0.3333333333333333 and Ratio Weight: 0.1084396467124632\n",
      "Ratio Head to tail: 0.5 and Ratio Weight: 0.4133148404993065\n",
      "12 210\n",
      "Ratio Head to tail: 0.12959381044487428 and Ratio Weight: 0.18338164251207728\n",
      "Ratio Head to tail: 0.21818181818181817 and Ratio Weight: 0.5162613536478172\n",
      "Ratio Head to tail: 0.3333333333333333 and Ratio Weight: 0.4364478114478115\n",
      "Ratio Head to tail: 2.0 and Ratio Weight: 0.21348314606741572\n",
      "67 517\n",
      "Ratio Head to tail: 1.0 and Ratio Weight: 0.043478260869565216\n",
      "1 1\n",
      "Ratio Head to tail: 0.09090909090909091 and Ratio Weight: 0.5833333333333334\n",
      "Ratio Head to tail: 1.0 and Ratio Weight: 0.37142857142857144\n",
      "2 22\n",
      "Ratio Head to tail: 0.04823151125401929 and Ratio Weight: 0.09542387178405735\n",
      "Ratio Head to tail: 0.36363636363636365 and Ratio Weight: 0.11550223476828982\n",
      "Ratio Head to tail: 1.0 and Ratio Weight: 0.2659321024419297\n",
      "15 311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get the top network contributors defined using the Paretian Binning strategy from 'Geosptaial Analysis Requires a Different Way of Thinking' by Bin Jiang. \n",
    "\n",
    "Key: Repository name\n",
    "Value: List of tob contributors\n",
    "'''\n",
    "\n",
    "def sep_bins(head_dict, history):\n",
    "   \n",
    "    head = {}\n",
    "    tail = {}\n",
    "    avg = np.mean(list(head_dict.values()))\n",
    "    for k,v in head_dict.items(): \n",
    "        if v < avg: \n",
    "            tail[k] = v\n",
    "        else: \n",
    "            head[k] = v\n",
    "            \n",
    "    history.append((head, tail))\n",
    "    ratio_head_to_tail = len(head)/len(tail)\n",
    "    ratio_weight = sum([x for x in tail.values()])/ sum([x for x in head.values()])\n",
    "    print(\"Ratio Head to tail: {} and Ratio Weight: {}\".format(ratio_head_to_tail, ratio_weight))\n",
    "    if ratio_head_to_tail < 0.5: #Note after 50% ratio of head to tail ratio weight starts to go down. \n",
    "        sep_bins(head, history)\n",
    "    return head, tail, history\n",
    "print(\"\\n\\n\")        \n",
    "pratian = []\n",
    "tails = {}\n",
    "head_total = 0\n",
    "\n",
    "for k,v in lib_producers.items(): \n",
    "    history = []\n",
    "    head, tail, history = sep_bins(lib_producers[k], history)\n",
    "    pratian.append({k:head})\n",
    "    tails[k] = history\n",
    "    head_total += len(head)\n",
    "    print (len(head), len(tail))\n",
    "head_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"tails.json\", \"w\") as file:\n",
    "    json.dump(tails, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A. Bipartite and Projection Graphs of Tail 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_bi(tails, up_tail):\n",
    "    '''\n",
    "    Creates bipartite graph\n",
    "    \n",
    "    return networkx graph object, and left and right side of graph\n",
    "    \n",
    "    pass in tails library created above\n",
    "    \n",
    "    pass in negative integer of how far up the tail to include\n",
    "    '''\n",
    "    \n",
    "    bip_bin = nx.Graph()\n",
    "\n",
    "    for lib, bins in tails.items(): \n",
    "        bip_bin.add_node(lib, bipartite=0)\n",
    "        if len(bins) > up_tail*-1: \n",
    "            #print(bins[-2])\n",
    "            for v in bins[up_tail]: #.items(): \n",
    "                #print(v.keys())\n",
    "                for n in v.keys(): \n",
    "                    #print(n)\n",
    "                    bip_bin.add_node(n, bipartite=1)\n",
    "                    bip_bin.add_edge(lib,n)\n",
    "        else: \n",
    "            bin_num = len(bins) *-1\n",
    "            for v in bins[bin_num]: #.items(): \n",
    "                for n in v.keys():\n",
    "                    bip_bin.add_node(n, bipartite=1)\n",
    "                    bip_bin.add_edge(lib,n)  \n",
    "\n",
    "    print(\"There are {} nodes in the bipartite graph\".format(len(bip_bin.nodes)))\n",
    "    \n",
    "    #For graph\n",
    "    top = [node for node in bip_bin.nodes() if bip_bin.nodes[node]['bipartite']==0]\n",
    "    bottom = [node for node in bip_bin.nodes() if bip_bin.nodes[node]['bipartite']==1]\n",
    "    \n",
    "    return bip_bin, top, bottom\n",
    "\n",
    "def make_proj(tails, up_tail): \n",
    "    '''\n",
    "    Creates contributor projection graph\n",
    "    \n",
    "    return networkx graph object, and left and right side of graph\n",
    "    \n",
    "    pass in tails library created above\n",
    "    \n",
    "    pass in negative integer of how far up the tail to include\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    proj_bin = nx.Graph()\n",
    "\n",
    "    for lib, bins in tails.items(): \n",
    "        #bip_2bin.add_node(lib, bipartite=0)\n",
    "        if len(bins) > up_tail*-1:\n",
    "            nodes = []\n",
    "            for v in bins[up_tail]: #.items(): \n",
    "                nodes += list(v.keys())\n",
    "            proj_bin.add_nodes_from(nodes)\n",
    "            edges = [p for p in itertools.combinations(nodes,2)]   \n",
    "            proj_bin.add_edges_from(edges) \n",
    "        else: \n",
    "            bin_num = len(bins) *-1\n",
    "            nodes = []\n",
    "            for v in bins[bin_num]:\n",
    "                nodes += list(v.keys())\n",
    "            proj_bin.add_nodes_from(nodes)\n",
    "            edges = [p for p in itertools.combinations(nodes,2)]   \n",
    "            proj_bin.add_edges_from(edges) \n",
    "\n",
    "    print(\"There are {} nodes in the projection graph\".format(len(proj_bin.nodes)))\n",
    "    \n",
    "    return proj_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_1bin, top, bottom = make_bi(tails, -1)\n",
    "proj_1bin = make_proj(tails, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj1_comps = list(nx.connected_components(proj_1bin))\n",
    "len(proj1_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(proj_1bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.local_efficiency(proj_1bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.global_efficiency(proj_1bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the libararies and most contributors\n",
    "multiplier = len(bottom)/len(top)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "pos = dict()\n",
    "pos.update( (n, (1.20, i*50)) for i, n in enumerate(bottom)) # put nodes from X at x=1\n",
    "pos.update( (n, (1.70, i*multiplier*50)) for i, n in enumerate(top) ) # put nodes from Y at x=2\n",
    "\n",
    "\n",
    "nx.draw(bip_1bin, pos=pos, with_labels=False)#, nodelist=top, node_size=2000, node_color='#FF0000', font_size=20)\n",
    "#nx.draw(bip_most, pos=pos, with_labels=True, nodelist=bottom, node_size=800, node_color = '#FFFF00', font_size=15)\n",
    "\n",
    "plt.title(\"Bipartite of Tail 1\", fontsize=20, fontweight=\"bold\")\n",
    "style = dict(size=15, color='blue', fontweight=\"bold\")\n",
    "plt.text(1.18,3300, \"Contributors\", **style)\n",
    "plt.text(1.68,3300, \"Libraries\", **style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(proj_1bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B. Bipartite and Projection Graphs of Tail 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_2bin, top, bottom = make_bi(tails, -2)\n",
    "proj_2bin = make_proj(tails, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2_comps = list(nx.connected_components(proj_2bin))\n",
    "len(proj2_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(proj_2bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.local_efficiency(proj_2bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.global_efficiency(proj_2bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get the libararies and most contributors\n",
    "top = [node for node in bip_2bin.nodes() if bip_2bin.nodes[node]['bipartite']==0]\n",
    "bottom = [node for node in bip_2bin.nodes() if bip_2bin.nodes[node]['bipartite']==1]\n",
    "multiplier = len(bottom)/len(top)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "pos = dict()\n",
    "pos.update( (n, (1.20, i*50)) for i, n in enumerate(bottom)) # put nodes from X at x=1\n",
    "pos.update( (n, (1.70, i*multiplier*50)) for i, n in enumerate(top) ) # put nodes from Y at x=2\n",
    "\n",
    "\n",
    "nx.draw(bip_2bin, pos=pos, with_labels=False)#, nodelist=top, node_size=2000, node_color='#FF0000', font_size=20)\n",
    "#nx.draw(bip_most, pos=pos, with_labels=True, nodelist=bottom, node_size=800, node_color = '#FFFF00', font_size=15)\n",
    "\n",
    "plt.title(\"Bipartites of Tail 2\", fontsize=20, fontweight=\"bold\")\n",
    "style = dict(size=15, color='blue', fontweight=\"bold\")\n",
    "#plt.text(1.18,38000, \"Contributors\", **style)\n",
    "#plt.text(1.68,38000, \"Libraries\", **style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_2bin = nx.Graph()\n",
    "\n",
    "for lib, bins in tails.items(): \n",
    "    #bip_2bin.add_node(lib, bipartite=0)\n",
    "    if len(bins) > 2: \n",
    "        for v in bins[-2]: #.items(): \n",
    "            nodes = list(v.keys())\n",
    "            proj_2bin.add_nodes_from(nodes)\n",
    "            edges = [p for p in itertools.combinations(nodes,2)]   \n",
    "            proj_2bin.add_edges_from(edges) \n",
    "    else: \n",
    "      for v in bins[-1]: #.items(): \n",
    "        nodes = list(v.keys())\n",
    "        proj_2bin.add_nodes_from(nodes)\n",
    "        edges = [p for p in itertools.combinations(nodes,2)]   \n",
    "        proj_2bin.add_edges_from(edges) \n",
    "\n",
    "len(proj_2bin.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(proj_2bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3C. Bipartite and Projection Graphs of Tail 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_3bin, top, bottom = make_bi(tails, -3)\n",
    "proj_3bin = make_proj(tails, -3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj3_comps = list(nx.connected_components(proj_3bin))\n",
    "len(proj3_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(proj_3bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.local_efficiency(proj_3bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.global_efficiency(proj_3bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the libararies and most contributors\n",
    "multiplier = len(bottom)/len(top)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "pos = dict()\n",
    "pos.update( (n, (1.20, i*50)) for i, n in enumerate(bottom)) # put nodes from X at x=1\n",
    "pos.update( (n, (1.70, i*multiplier*50)) for i, n in enumerate(top) ) # put nodes from Y at x=2\n",
    "\n",
    "\n",
    "nx.draw(bip_3bin, pos=pos, with_labels=False)#, nodelist=top, node_size=2000, node_color='#FF0000', font_size=20)\n",
    "#nx.draw(bip_most, pos=pos, with_labels=True, nodelist=bottom, node_size=800, node_color = '#FFFF00', font_size=15)\n",
    "\n",
    "plt.title(\"Bipartites of Tail 3\", fontsize=20, fontweight=\"bold\")\n",
    "style = dict(size=15, color='blue', fontweight=\"bold\")\n",
    "#plt.text(1.18,38000, \"Contributors\", **style)\n",
    "#plt.text(1.68,38000, \"Libraries\", **style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(proj_3bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D. Bipartite and Projection Graphs of Tail 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_4bin, top, bottom = make_bi(tails, -4)\n",
    "proj_4bin = make_proj(tails, -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj4_comps = list(nx.connected_components(proj_4bin))\n",
    "len(proj4_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(proj_4bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.local_efficiency(proj_4bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.global_efficiency(proj_4bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(proj_4bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3E. Bipartite and Projection Graphs of Tail 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_5bin, top, bottom = make_bi(tails, -5)\n",
    "proj_5bin = make_proj(tails, -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj5_comps = list(nx.connected_components(proj_5bin))\n",
    "len(proj5_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(proj_5bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.local_efficiency(proj_5bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.global_efficiency(proj_5bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = []\n",
    "num_edges = []\n",
    "num_components = []\n",
    "assortativity = []\n",
    "density = []\n",
    "local_e = []\n",
    "global_e = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(\"You are on run {}\".format(i))\n",
    "    proj_bin = make_proj(tails, i *-1)\n",
    "    num_nodes.append(len(proj_bin.nodes))\n",
    "    num_edges.append(len(proj_bin.edges))\n",
    "    num_components.append(len(list(nx.connected_components(proj_bin))))\n",
    "    assortativity.append(nx.degree_assortativity_coefficient(proj_bin))\n",
    "    density.append(nx.density(proj_bin))\n",
    "    local_e.append(nx.local_efficiency(proj_bin))\n",
    "    print(\"local complete\")\n",
    "    global_e.append(nx.global_efficiency(proj_bin))\n",
    "    \n",
    "    \n",
    "    \n",
    "### Collect metrics for all network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7383 nodes in the projection graph\n"
     ]
    }
   ],
   "source": [
    "num_nodes5 = []\n",
    "num_edges5 = []\n",
    "num_components5 = []\n",
    "assortativity5 = []\n",
    "density5 = []\n",
    "local_e5 = []\n",
    "global_e5 = []\n",
    "\n",
    "\n",
    "#print(\"You are on run {}\".format(i))\n",
    "proj_bin = make_proj(tails, -5)\n",
    "num_nodes5.append(len(proj_bin.nodes))\n",
    "num_edges5.append(len(proj_bin.edges))\n",
    "#num_components.append(len(list(nx.connected_components(proj_bin))))\n",
    "#assortativity.append(nx.degree_assortativity_coefficient(proj_bin))\n",
    "#density.append(nx.density(proj_bin))\n",
    "local_e5.append(nx.local_efficiency(proj_bin))\n",
    "print(\"local complete\")\n",
    "#global_e.append(nx.global_efficiency(proj_bin))\n",
    "    \n",
    "    \n",
    "    \n",
    "### Collect metrics for all network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitivity = []\n",
    "triangles = []\n",
    "clustering = []\n",
    "coms_sum = []\n",
    "coms_exp = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(\"You are on run {}\".format(i))\n",
    "    proj_bin = make_proj(tails, i *-1)\n",
    "    transitivity.append(nx.transitivity(proj_bin))\n",
    "    print(\"trans complete\")\n",
    "    triangles.append(nx.triangles(proj_bin))\n",
    "    print(\"triangles complete\")\n",
    "    clustering.append(nx.average_clustering(proj_bin))\n",
    "    print(\"clustering complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "transitivity,clustering,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_sum = []\n",
    "coms_exp = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(\"You are on run {}\".format(i))\n",
    "    proj_bin = make_proj(tails, i *-1)\n",
    "    if len(list(nx.connected_components(proj_bin))) == 1: \n",
    "                print(\"coms strting\")\n",
    "                coms_sum.append(nx.communicability(proj_bin))\n",
    "                print(\"coms mid\")\n",
    "                coms_exp.append(nx.communicability_exp(proj_bin))\n",
    "                print(\"coms ending\")\n",
    "    else: \n",
    "                coms_sum.append(\"disconnected\")\n",
    "                coms_exp.append(\"disconnected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "project_dict = {\"number of nodes\" : num_nodes, \"number of edges\": num_edges, \"number of components\": num_components, \"assortativity\" : assortativity, \"density\": density,\n",
    "                \"local efficiency\":local_e, \"global efficiency\" : global_e}\n",
    "\n",
    "\n",
    "with open(\"projection_graph.json\", \"w\") as file:\n",
    "    json.dump(project_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_bin = make_proj(tails, -5)\n",
    "num_nodes.append(len(nx.nodes(proj_bin)))\n",
    "num_edges.append(len(proj_bin.edges))\n",
    "num_components.append(len(list(nx.connected_components(proj_bin))))\n",
    "assortativity.append(nx.degree_assortativity_coefficient(proj_bin))\n",
    "density.append(nx.density(proj_bin))\n",
    "global_e.append(nx.global_efficiency(proj_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dict = {\"number of nodes\" : num_nodes, \"number of edges\": num_edges, \"number of components\": num_components, \"assortativity\" : assortativity, \"density\": density,\n",
    "                \"local efficiency\":local_e, \"global efficiency\" : global_e}\n",
    "project_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5): \n",
    "    print(project_dict[\"number of edges\"][i]/project_dict[\"number of nodes\"][i])\n",
    "    print(project_dict[\"number of nodes\"][i]/project_dict[\"number of edges\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "sns.relplot(project_dict[\"number of nodes\"],project_dict[\"number of edges\"],kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(project_dict[\"global efficiency\"],project_dict[\"density\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO LONGER USED ------Projection by magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of number one contributors for each library \n",
    "most_list = []\n",
    "for k,v in lib_producers.items():\n",
    "    most = [\"\",0, k]\n",
    "    for k2,v2 in v.items(): \n",
    "        if v2 > most[1]: \n",
    "            most[0] = k2\n",
    "            most[1] = v2\n",
    "    most_list.append(most)\n",
    "most_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "# key = libraray\n",
    "#value = list of contributors\n",
    "pratian_contribs = {}\n",
    "for prat in pratian: \n",
    "    key = list(prat.keys())[0]\n",
    "    pratian_contribs[key] = list(prat[key].keys())\n",
    "pratian_contribs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of number one contributors for each library \n",
    "most_list = []\n",
    "for k,v in lib_producers.items():\n",
    "    most = [\"\",0, k]\n",
    "    for k2,v2 in v.items(): \n",
    "        if v2 > most[1]: \n",
    "            most[0] = k2\n",
    "            most[1] = v2\n",
    "    most_list.append(most)\n",
    "most_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_contribs['cpython']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_most = nx.Graph()\n",
    "\n",
    "for k,v in top_contribs.items(): \n",
    "    bip_most.add_node(k, bipartite=0)\n",
    "    for n in v: \n",
    "        bip_most.add_node(n[0], bipartite=1)\n",
    "        bip_most.add_edge(k,n[0])\n",
    "\n",
    "len(bip_most.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the libararies and most contributors\n",
    "top = [node for node in bip_most.nodes() if bip_most.nodes[node]['bipartite']==0]\n",
    "bottom = [node for node in bip_most.nodes() if bip_most.nodes[node]['bipartite']==1]\n",
    "multiplier = len(bottom)/len(top)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,12)})\n",
    "pos = dict()\n",
    "pos.update( (n, (1.20, i*50)) for i, n in enumerate(bottom)) # put nodes from X at x=1\n",
    "pos.update( (n, (1.70, i*multiplier*50)) for i, n in enumerate(top) ) # put nodes from Y at x=2\n",
    "\n",
    "\n",
    "nx.draw(bip_most, pos=pos, with_labels=False)#, nodelist=top, node_size=2000, node_color='#FF0000', font_size=20)\n",
    "#nx.draw(bip_most, pos=pos, with_labels=True, nodelist=bottom, node_size=800, node_color = '#FFFF00', font_size=15)\n",
    "\n",
    "plt.title(\"Major Contributors to the Top Networks\", fontsize=20, fontweight=\"bold\")\n",
    "style = dict(size=15, color='blue', fontweight=\"bold\")\n",
    "plt.text(1.18,2100, \"Contributors\", **style)\n",
    "plt.text(1.68,2100, \"Libraries\", **style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_most = nx.Graph()\n",
    "\n",
    "for k,v in top_contribs.items(): \n",
    "    nodes = list(zip(*v))[0]\n",
    "    proj_most.add_nodes_from(nodes)\n",
    "    edges = [p for p in itertools.combinations(nodes,2)]   \n",
    "    proj_most.add_edges_from(edges)\n",
    "\n",
    "proj_most.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(proj_most, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
